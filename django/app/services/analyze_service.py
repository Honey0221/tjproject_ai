import os
import joblib
import time
import torch
from crawling.bigKindsCrawling import search_bigkinds
from crawling.latestNewsCrawling import get_latest_articles
from app.utils.emotion_model_loader import (
    MODEL_DIR, ALLOWED_MODELS, embedding_model, hf_tokenizer, hf_model, id2label
)
from fastapi import HTTPException


def analyze_news(req):
    """
    í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ìµœì‹  ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì„ ìˆ˜ì§‘í•œ í›„,
    ì„ íƒëœ ëª¨ë¸(vote, stack, transformer)ë¡œ ê°ì • ë¶„ì„ ìˆ˜í–‰
    """
    articles = get_latest_articles(req.keyword, req.max_articles, headless=req.headless)
    if not articles:
        raise HTTPException(status_code=204, detail="í•´ë‹¹ í‚¤ì›Œë“œë¡œ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    return _analyze_articles(articles, req.model, req.keyword)


def analyze_news_filtered(req):
    """
    í†µí•©ë¶„ë¥˜, ì‚¬ê±´ì‚¬ê³ ë¶„ë¥˜, ë‚ ì§œ ë²”ìœ„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ
    BigKindsì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘ í›„ ê°ì • ë¶„ì„
    """
    from crawling.driver import undetected_driver

    driver = undetected_driver(headless=req.headless)

    try:
        articles = search_bigkinds(
            driver=driver,
            keyword=req.keyword,
            unified_category=req.unified_category,
            incident_category=req.incident_category,
            start_date=req.start_date,
            end_date=req.end_date,
            date_method=req.date_method,
            period_label=req.period_label,
            max_articles=req.max_articles
        )
    except RuntimeError as e:
        driver.quit()
        raise HTTPException(status_code=204, detail=f"ê¸°ì‚¬ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
    except Exception as e:
        driver.quit()
        raise HTTPException(status_code=500, detail=f"ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜: {str(e)}")

    driver.quit()

    if not articles:
        raise HTTPException(status_code=204, detail="ê²€ìƒ‰ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

    return _analyze_articles(articles, req.model, req.keyword)


def emotion_batch(req):
    """
    ê°ì • ë¶„ì„ ì—†ì´ ê¸°ì‚¬ë§Œ ìˆ˜ì§‘í•˜ëŠ” API (ë°ì´í„° ì €ì¥ ë˜ëŠ” í›„ì²˜ë¦¬ìš©)
    """
    from crawling.driver import undetected_driver

    start_date = req.start_date or "2025-01-01"
    end_date = req.end_date or time.strftime("%Y-%m-%d")

    driver = undetected_driver(headless=True)

    try:
        articles = search_bigkinds(
            driver=driver,
            keyword=req.keyword,
            unified_category=req.unified_category,
            incident_category=req.incident_category,
            start_date=start_date,
            end_date=end_date,
            date_method=req.date_method,
            period_label=req.period_label,
            max_articles=req.max_articles
        )
    except Exception as e:
        driver.quit()
        raise HTTPException(status_code=500, detail=f"ê¸°ì‚¬ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    driver.quit()

    if not articles:
        raise HTTPException(status_code=204, detail="ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

    return {
        "count": len(articles),
        "data": articles
    }


def _analyze_articles(articles, model_key, keyword):
    """
    ì£¼ì–´ì§„ ê¸°ì‚¬ ëª©ë¡(articles)ì— ëŒ€í•´ ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” ë‚´ë¶€ í•¨ìˆ˜

    - transformer: HuggingFace ê¸°ë°˜ ëª¨ë¸ ì‚¬ìš©
    - vote/stack: ì „í†µ ML ëª¨ë¸ ì‚¬ìš© (ì‚¬ì „ ì„ë² ë”© + joblib ë¡œë”©)
    """

    results = []

    if model_key not in ALLOWED_MODELS:
        raise HTTPException(status_code=400, detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ì…ë‹ˆë‹¤: {model_key}")

    for article in articles:
        text = article.get("summary") or article.get("title", "")
        if not text.strip():
            continue

        try:
            # ğŸ” HuggingFace ê¸°ë°˜ transformer ëª¨ë¸
            if model_key == "transformer":
                inputs = hf_tokenizer(text, return_tensors="pt", truncation=True, padding=True)
                with torch.no_grad():
                    outputs = hf_model(**inputs)
                    probs = torch.nn.functional.softmax(outputs.logits, dim=1)
                    conf, pred = torch.max(probs, dim=1)
                label = id2label[pred.item()]
                confidence = round(conf.item(), 4)

            # ğŸ” ì „í†µ ML ì•™ìƒë¸” ëª¨ë¸ (Voting/Stacking)
            else:
                model_path = os.path.join(MODEL_DIR, f"{model_key}.joblib")
                if not os.path.exists(model_path):
                    raise HTTPException(status_code=500, detail=f"ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}")

                model = joblib.load(model_path)
                embedding = embedding_model.encode([text], show_progress_bar=False)
                prediction = model.predict(embedding)[0]
                confidence = model.predict_proba(embedding)[0].max()
                label = id2label[prediction]

            results.append({
                "title": article.get("title", ""),
                "summary": article.get("summary", ""),
                "press": article.get("press", ""),
                "date": article.get("date", ""),
                "link": article.get("link", ""),
                "label": label,
                "confidence": confidence
            })

        except Exception as e:
            raise HTTPException(status_code=500, detail=f"ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    if not results:
        raise HTTPException(status_code=204, detail="ë¶„ì„ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

    return {
        "keyword": keyword,
        "count": len(results),
        "results": results
    }
